{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex  Age  Fare  Cabin  Embarked  \\\n",
       "0            1         0       3     1    0    1     0      6         0   \n",
       "1            2         1       1     3    1    2     4      3         1   \n",
       "2            3         1       3     2    1    1     1      6         0   \n",
       "3            4         1       1     3    1    2     4      3         0   \n",
       "4            5         0       3     1    0    2     1      6         0   \n",
       "\n",
       "   Family  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('titanic_data.csv')\n",
    "pipe = joblib.load(f'titanic_pipe.pkl')\n",
    "pipe.fit(data_df)\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['Pclass', 'Name', 'Sex',\n",
       "                                                   'Age', 'Fare', 'Cabin',\n",
       "                                                   'Embarked', 'Family'])]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X = data_df.copy()\n",
    "\n",
    "del titanic_X['PassengerId']\n",
    "del titanic_X['Survived']\n",
    "\n",
    "titanic_Y = np.array(data_df[['Survived']])\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "   model_selection.train_test_split(titanic_X, titanic_Y, test_size=0.3, random_state=0)\n",
    "\n",
    "x_train = pipe.transform(x_train)\n",
    "x_test = pipe.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model # LogisticRegression()\n",
    "from sklearn import neighbors # KNeighborsClassifier()\n",
    "from sklearn.svm import SVC # SVC(gamma='auto')\n",
    "from sklearn import tree # DecisionTreeClassifier()\n",
    "from sklearn import ensemble # RandomForestClassifier()\n",
    "from sklearn import naive_bayes # BernoulliNB()\n",
    "from sklearn import cluster # KMeans(random_state=0)\n",
    "from sklearn import decomposition # PCA(n_components=1)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Logistic', linear_model.LogisticRegression()),\n",
    "    ('KNN', neighbors.KNeighborsClassifier(16)),\n",
    "    ('SVM', SVC(kernel='rbf', C=100, gamma=0.01)),\n",
    "    ('DecisionTree', tree.DecisionTreeClassifier(random_state = 0, max_depth = 4)),\n",
    "    ('RandomForest', ensemble.RandomForestClassifier(random_state = 0, n_estimators = 100, max_depth = 6)),\n",
    "    ('NaiveBayes', naive_bayes.BernoulliNB(alpha=10)),\n",
    "    ('XGBoost', XGBClassifier(seed = 0, n_estimators = 200, max_depth = 3, verbosity=0)),\n",
    "    ('LightGBM', LGBMClassifier(random_state=0, n_estimators = 200, max_depth = 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic:  0.8432835820895522\n",
      "KNN:  0.8283582089552238\n",
      "SVM:  0.8432835820895522\n",
      "DecisionTree:  0.8395522388059702\n",
      "RandomForest:  0.835820895522388\n",
      "NaiveBayes:  0.7947761194029851\n",
      "XGBoost:  0.8208955223880597\n",
      "LightGBM:  0.8395522388059702\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    print(f'{name}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminat Analysis: 0.835820895522388\n"
     ]
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(x_train.todense(), y_train)\n",
    "print('Linear Discriminat Analysis:', accuracy_score(clf.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X = pipe.transform(titanic_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.8101 0.8258 0.8427 0.8146 0.8596]\n",
      "평균 검증 정확도: 0.8305504990270542\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LGBMClassifier(random_state=0, n_estimators = 200, max_depth = 2), titanic_X, titanic_Y, scoring='accuracy', cv=5)\n",
    "print('교차 검증별 정확도:',np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Params: {'C': 1.0, 'penalty': 'l2'}\n",
      "Logistic Regression Score: 0.8432835820895522\n"
     ]
    }
   ],
   "source": [
    "logistic_param_grid = {'C': np.logspace(-3,3,7),\n",
    "                       'penalty': [\"l1\",\"l2\"]}\n",
    "\n",
    "logistic_grid = GridSearchCV(\n",
    "    linear_model.LogisticRegression(), logistic_param_grid, refit=True, cv=10, scoring='accuracy')\n",
    "\n",
    "logistic_grid.fit(x_train, y_train)\n",
    "\n",
    "print('GridSearch Best Params:', logistic_grid.best_params_)\n",
    "print(f'Logistic Regression Score:', accuracy_score(y_test, logistic_grid.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.79\n",
      "Precision Score: 0.79\n",
      "F1 Score: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "print('Recall Score:', recall_score(y_test, logistic_grid.predict(x_test)))\n",
    "print('Precision Score:', precision_score(y_test, logistic_grid.predict(x_test)))\n",
    "print('F1 Score:', f1_score(y_test, logistic_grid.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Params: {'n_neighbors': 16}\n",
      "KNN Score: 0.8283582089552238\n"
     ]
    }
   ],
   "source": [
    "knn_param_grid = {'n_neighbors': list(range(1,31))}\n",
    "\n",
    "knn_grid = GridSearchCV(\n",
    "    neighbors.KNeighborsClassifier(), knn_param_grid, refit=True, cv=10, scoring='accuracy')\n",
    "\n",
    "knn_grid.fit(x_train, y_train)\n",
    "\n",
    "print('GridSearch Best Params:', knn_grid.best_params_)\n",
    "print(f'KNN Score:', accuracy_score(y_test, knn_grid.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Params: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "SVC Score: 0.8246268656716418\n"
     ]
    }
   ],
   "source": [
    "svc_param_grid = {'C': [0.1,1,10,100,1000], \n",
    "                 'gamma': [1,0.1,0.01,0.001,0.0001],\n",
    "                 'kernel': ['rbf']}\n",
    "\n",
    "svc_grid = GridSearchCV(\n",
    "    SVC(), svc_param_grid, refit=True, cv=10, scoring='accuracy')\n",
    "\n",
    "svc_grid.fit(x_train, y_train)\n",
    "\n",
    "print('GridSearch Best Params:', svc_grid.best_params_)\n",
    "print(f'SVC Score:', accuracy_score(svc_grid.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Params: {'criterion': 'entropy', 'max_depth': 6, 'random_state': 0}\n",
      "Decision Tree Score: 0.832089552238806\n"
     ]
    }
   ],
   "source": [
    "dtree_param_grid = {'criterion': ['gini', 'entropy'],\n",
    "                    'max_depth': [2,4,6,8,10,12],\n",
    "                    'random_state': [0]}\n",
    "\n",
    "dtree_grid = GridSearchCV(\n",
    "    tree.DecisionTreeClassifier(), dtree_param_grid, refit=True, cv=10, scoring='accuracy')\n",
    "\n",
    "dtree_grid.fit(x_train, y_train)\n",
    "\n",
    "print('GridSearch Best Params:', dtree_grid.best_params_)\n",
    "print(f'Decision Tree Score:', accuracy_score(dtree_grid.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Params: {'max_depth': 6, 'n_estimators': 100, 'random_state': 0}\n",
      "Random Forest Score: 0.835820895522388\n"
     ]
    }
   ],
   "source": [
    "rforest_param_grid = {'n_estimators': [100,200,300,1000],\n",
    "                      'max_depth': [2,4,6,8,10,12],\n",
    "                      'random_state': [0]}\n",
    "\n",
    "rforest_grid = GridSearchCV(\n",
    "    ensemble.RandomForestClassifier(), rforest_param_grid, refit=True, cv=10, scoring='accuracy')\n",
    "\n",
    "rforest_grid.fit(x_train, y_train)\n",
    "\n",
    "print('GridSearch Best Params:', rforest_grid.best_params_)\n",
    "print(f'Random Forest Score:', accuracy_score(rforest_grid.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Best Params: {'alpha': 10.0}\n",
      "Naive Bayes Score: 0.7947761194029851\n"
     ]
    }
   ],
   "source": [
    "bayes_param_grid = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "bayes_grid = GridSearchCV(\n",
    "    naive_bayes.BernoulliNB(), bayes_param_grid, refit=True, cv=10, scoring='accuracy')\n",
    "\n",
    "bayes_grid.fit(x_train, y_train)\n",
    "\n",
    "print('GridSearch Best Params:', bayes_grid.best_params_)\n",
    "print(f'Naive Bayes Score:', accuracy_score(bayes_grid.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========== 테스트 코드 =========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "1. 나이 결측치 행 제거\n",
    "\n",
    "2. 나이 결측치 평균값 처리\n",
    "3. 나이 및 선실 결측치 행 제거\n",
    "4. 나이 및 선실 결측치 평균값 처리\n",
    "5. 나이 결측치 행 제거 및 나이 구간화\n",
    "6. 나이 결측치 행 제거 (One-Hot Encoding 적용 안함)\n",
    "7. 나이 및 선실 결측치 행 제거 (One-Hot Encoding 적용 안함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('titanic_data.csv')\n",
    "\n",
    "data_df_age = data_df[ data_df['Age'] > 0 ].copy()\n",
    "data_df_age['Age'] = data_df_age['Age'].astype(int)\n",
    "y_data_age = np.array(data_df_age[['Survived']])\n",
    "\n",
    "del data_df_age['PassengerId']\n",
    "\n",
    "data_df_cab = data_df_age[ data_df_age['Cabin'].notnull() ].copy()\n",
    "data_df_cab['Cabin'] = data_df_cab['Cabin'].astype(int)\n",
    "y_data_cab = np.array(data_df_cab[['Survived']])\n",
    "\n",
    "del data_df_age['Cabin']\n",
    "\n",
    "del data_df_age['Survived']\n",
    "del data_df_cab['Survived']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_df_age[['Age']])\n",
    "data_df_age['Age'] = scaler.transform(data_df_age[['Age']])\n",
    "\n",
    "x_data_age = np.array(data_df_age)\n",
    "x_data_cab = np.array(data_df_cab)\n",
    "\n",
    "df_list = list()\n",
    "\n",
    "for i in range(1,6):\n",
    "    df_list.append(pd.read_csv(f'titanic_data_{i}.csv'))\n",
    "\n",
    "pipe_list = list()\n",
    "\n",
    "for i in [1, 1, 2, 2, 3]:\n",
    "    pipe_list.append(joblib.load(f'titanic_pipe_{i}.pkl'))\n",
    "\n",
    "data_list = list()\n",
    "\n",
    "for data, pipe in zip(df_list, pipe_list):\n",
    "    pipe.fit(data)\n",
    "    titanic_X = pipe.transform(data)\n",
    "    titanic_Y = np.array(data[['Survived']])\n",
    "    data_list.append((titanic_X, titanic_Y))\n",
    "\n",
    "data_list.append((x_data_age, y_data_age))\n",
    "data_list.append((x_data_cab, y_data_cab))\n",
    "\n",
    "tdata_list = list()\n",
    "\n",
    "for titanic_X, titanic_Y in data_list:\n",
    "   x_train, x_test, y_train, y_test = \\\n",
    "      model_selection.train_test_split(titanic_X, titanic_Y, test_size=0.3, random_state=0)\n",
    "   tdata_list.append((x_train, x_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "- Data 3: Decision Tree에서 최고점(0.839), 모든 모델과 Stacking 시도\n",
    "\n",
    "- Data 4: KNN에서 최고점(0.835), 모든 모델과 Stacking 시도\n",
    "- Data 6: 로지스틱 회귀에서 최고점(0.827), 모든 모델과 Stacking 시도\n",
    "- 나머지 데이터는 딱히 필요 없음 (Data 7은 최악)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model # LogisticRegression()\n",
    "from sklearn import neighbors # KNeighborsClassifier()\n",
    "from sklearn.svm import SVC # SVC(gamma='auto')\n",
    "from sklearn import tree # DecisionTreeClassifier()\n",
    "from sklearn import ensemble # RandomForestClassifier()\n",
    "from sklearn import naive_bayes # BernoulliNB()\n",
    "from sklearn import cluster # KMeans(random_state=0)\n",
    "from sklearn import decomposition # PCA(n_components=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- Max: 6번 데이터에서 0.82\n",
    "\n",
    "- Min: 7번 데이터에서 0.78\n",
    "- C를 높이면 6번 데이터 점수가 상승"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 1:  0.8093023255813954\n",
      "Accuracy Score 2:  0.8059701492537313\n",
      "Accuracy Score 3:  0.8035714285714286\n",
      "Accuracy Score 4:  0.8134328358208955\n",
      "Accuracy Score 5:  0.8046511627906977\n",
      "Accuracy Score 6:  0.827906976744186\n",
      "Accuracy Score 7:  0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "\n",
    "for i, (x_train, x_test, y_train, y_test) in enumerate(tdata_list):\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model = model.fit(x_train, y_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i+1}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "- Max: 4번 데이터에서 0.83\n",
    "\n",
    "- Min: 7번 데이터에서 0.57\n",
    "- 6번 데이터는 성적이 적당 (0.79)\n",
    "- K값을 더 높이면 6번 데이터 점수 상승"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 1:  0.8093023255813954\n",
      "Accuracy Score 2:  0.8059701492537313\n",
      "Accuracy Score 3:  0.7857142857142857\n",
      "Accuracy Score 4:  0.835820895522388\n",
      "Accuracy Score 5:  0.8093023255813954\n",
      "Accuracy Score 6:  0.7906976744186046\n",
      "Accuracy Score 7:  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "best_k = [23, 19, 19, 27, 33, 9, 6]\n",
    "\n",
    "for i, ((x_train, x_test, y_train, y_test), k) in enumerate(zip(tdata_list, best_k)):\n",
    "    model = neighbors.KNeighborsClassifier(k)\n",
    "    model.fit(x_train, y_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i+1}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC\n",
    "- Max: 3번 데이터에서 0.82\n",
    "\n",
    "- Min: 7번 데이터에서 0.66\n",
    "- 6번 데이터 성적은 적당 (0.79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 1:  0.8046511627906977\n",
      "Accuracy Score 2:  0.7947761194029851\n",
      "Accuracy Score 3:  0.8214285714285714\n",
      "Accuracy Score 4:  0.7910447761194029\n",
      "Accuracy Score 5:  0.7906976744186046\n",
      "Accuracy Score 6:  0.8186046511627907\n",
      "Accuracy Score 7:  0.6607142857142857\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "\n",
    "for i, (x_train, x_test, y_train, y_test) in enumerate(tdata_list):\n",
    "    model = SVC(gamma='auto')\n",
    "    model.fit(x_train, y_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i+1}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "- Max: 3번 데이터에서 0.82\n",
    "\n",
    "- Min: 5번 데이터에서 0.79\n",
    "- 6번 데이터는 성적이 우수 (0.81)\n",
    "- 모든 데이터에서 depth 4가 최적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 1:  0.8186046511627907\n",
      "Accuracy Score 2:  0.8171641791044776\n",
      "Accuracy Score 3:  0.8392857142857143\n",
      "Accuracy Score 4:  0.8171641791044776\n",
      "Accuracy Score 5:  0.8093023255813954\n",
      "Accuracy Score 6:  0.8186046511627907\n",
      "Accuracy Score 7:  0.8214285714285714\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "\n",
    "for i, (x_train, x_test, y_train, y_test) in enumerate(tdata_list):\n",
    "    model = tree.DecisionTreeClassifier(random_state = 0, max_depth = 4)\n",
    "    model.fit(x_train, y_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i+1}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "- Max: 6번 데이터에서 0.82\n",
    "\n",
    "- Min: 3번 데이터에서 0.78\n",
    "- 3, 4번 데이터는 depth 3, 6번 데이터는 depth 4가 최적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 1:  0.8046511627906977\n",
      "Accuracy Score 2:  0.7910447761194029\n",
      "Accuracy Score 3:  0.7857142857142857\n",
      "Accuracy Score 4:  0.8134328358208955\n",
      "Accuracy Score 5:  0.813953488372093\n",
      "Accuracy Score 6:  0.8232558139534883\n",
      "Accuracy Score 7:  0.8035714285714286\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "\n",
    "for i, (x_train, x_test, y_train, y_test) in enumerate(tdata_list):\n",
    "    model = ensemble.RandomForestClassifier(random_state = 0, n_jobs = -1, n_estimators = 100, max_depth = 3)\n",
    "    model.fit(x_train, y_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i+1}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 1:  0.6607142857142857\n",
      "Accuracy Score 2:  0.7857142857142857\n",
      "Accuracy Score 3:  0.8035714285714286\n",
      "Accuracy Score 4:  0.75\n",
      "Accuracy Score 5:  0.75\n",
      "Accuracy Score 6:  0.7678571428571429\n",
      "Accuracy Score 7:  0.7321428571428571\n",
      "Accuracy Score 8:  0.7321428571428571\n",
      "Accuracy Score 9:  0.6964285714285714\n",
      "Accuracy Score 10:  0.7321428571428571\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "\n",
    "x_train, x_test, y_train, y_test = tdata_list[6]\n",
    "for i in range(1,11):\n",
    "    model = ensemble.RandomForestClassifier(random_state = 0, n_jobs = -1, n_estimators = 100, max_depth = i)\n",
    "    model.fit(x_train, y_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "- Max: 3번 데이터에서 0.82\n",
    "\n",
    "- Min: 7번 데이터에서 0.73\n",
    "- 6번 데이터는 성적이 좋음 (0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 1:  0.7674418604651163\n",
      "Accuracy Score 2:  0.7761194029850746\n",
      "Accuracy Score 3:  0.8214285714285714\n",
      "Accuracy Score 4:  0.7723880597014925\n",
      "Accuracy Score 5:  0.7488372093023256\n",
      "Accuracy Score 6:  0.7906976744186046\n",
      "Accuracy Score 7:  0.7321428571428571\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "\n",
    "for i, (x_train, x_test, y_train, y_test) in enumerate(tdata_list):\n",
    "    model = naive_bayes.BernoulliNB()\n",
    "    model.fit(x_train, y_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i+1}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means (ㅎㅎ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 1:  0.08837209302325581\n",
      "Accuracy Score 2:  0.31343283582089554\n",
      "Accuracy Score 3:  0.05357142857142857\n",
      "Accuracy Score 4:  0.13059701492537312\n",
      "Accuracy Score 5:  0.27906976744186046\n",
      "Accuracy Score 6:  0.12558139534883722\n",
      "Accuracy Score 7:  0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "\n",
    "for i, (x_train, x_test, y_train, y_test) in enumerate(tdata_list):\n",
    "    model = cluster.KMeans()\n",
    "    model.fit(x_train, y_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i+1}: ', accuracy_score(model.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (잘 모르겠다ㅎㅎ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PCA does not support sparse input. See TruncatedSVD for a possible alternative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/cuz/Downloads/AI_SCHOOL/Semi-project 2 (Feature engineering _ applying ML algorithms)/my/ml_others.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cuz/Downloads/AI_SCHOOL/Semi-project%202%20%28Feature%20engineering%20_%20applying%20ML%20algorithms%29/my/ml_others.ipynb#ch0000021?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (x_train, x_test, y_train, y_test) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tdata_list):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cuz/Downloads/AI_SCHOOL/Semi-project%202%20%28Feature%20engineering%20_%20applying%20ML%20algorithms%29/my/ml_others.ipynb#ch0000021?line=3'>4</a>\u001b[0m     model \u001b[39m=\u001b[39m decomposition\u001b[39m.\u001b[39mPCA()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cuz/Downloads/AI_SCHOOL/Semi-project%202%20%28Feature%20engineering%20_%20applying%20ML%20algorithms%29/my/ml_others.ipynb#ch0000021?line=4'>5</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(x_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cuz/Downloads/AI_SCHOOL/Semi-project%202%20%28Feature%20engineering%20_%20applying%20ML%20algorithms%29/my/ml_others.ipynb#ch0000021?line=5'>6</a>\u001b[0m     model_list\u001b[39m.\u001b[39mappend(model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cuz/Downloads/AI_SCHOOL/Semi-project%202%20%28Feature%20engineering%20_%20applying%20ML%20algorithms%29/my/ml_others.ipynb#ch0000021?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy Score \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m, accuracy_score(model\u001b[39m.\u001b[39mtransform(x_test), y_test))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:382\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=364'>365</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=365'>366</a>\u001b[0m     \u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=366'>367</a>\u001b[0m \n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=367'>368</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=379'>380</a>\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=380'>381</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=381'>382</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=382'>383</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:425\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=421'>422</a>\u001b[0m \u001b[39m# Raise an error for sparse input.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=422'>423</a>\u001b[0m \u001b[39m# This is more informative than the generic one raised by check_array.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=423'>424</a>\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=424'>425</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=425'>426</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=426'>427</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=427'>428</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=429'>430</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=430'>431</a>\u001b[0m     X, dtype\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32], ensure_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=431'>432</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/sklearn/decomposition/_pca.py?line=433'>434</a>\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: PCA does not support sparse input. See TruncatedSVD for a possible alternative."
     ]
    }
   ],
   "source": [
    "model_list = list()\n",
    "\n",
    "for i, (x_train, x_test, y_train, y_test) in enumerate(tdata_list):\n",
    "    model = decomposition.PCA()\n",
    "    model.fit(x_train)\n",
    "    model_list.append(model)\n",
    "    print(f'Accuracy Score {i+1}: ', accuracy_score(model.transform(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
